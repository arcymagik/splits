%
% Niniejszy plik stanowi przyk³ad formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet u¿ytych poleceñ mo¿na wykorzystywaæ do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrze¿one.
%
% Copyright (c) 2001 by Marcin Woliñski <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie 
% - Seweryn Kar³owicz, 05.05.2006
% dodaj opcjê [licencjacka] dla pracy licencjackiej
\documentclass{pracamgr}

\usepackage{polski}

\usepackage{tikz}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\algrenewcommand\Return{\State \algorithmicreturn{} }%

%Jesli uzywasz kodowania polskich znakow ISO-8859-2 nastepna linia powinna byc 
%odkomentowana
\usepackage[latin2]{inputenc}
%Jesli uzywasz kodowania polskich znakow CP-1250 to ta linia powinna byc 
%odkomentowana
%\usepackage[cp1250]{inputenc}
%\usepackage[utf8]{inputenc}

% Dane magistranta:

\author{Damian Ha³as}

\nralbumu{292612}

\title{Sztuczna inteligencja w grze Splits}

\tytulang{Artificial intelligence in the game Splits}

%kierunek: Matematyka, Informatyka, ...
\kierunek{Informatyka}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podaæ tytu³/stopieñ imiê i nazwisko opiekuna
% Instytut
% ew. Wydzia³ ew. Uczelnia (je¿eli nie MIM UW))
\opiekun{dra Jakuba Pawlewicza\\
  Instytut Informatyki\\
  }

% miesi±c i~rok:
\date{Wrzesieñ 2014}

%Podaæ dziedzinê wg klasyfikacji Socrates-Erasmus:
\dziedzina{ 
%11.0 Matematyka, Informatyka:\\ 
%11.1 Matematyka\\ 
%11.2 Statystyka\\ 
%11.3 Informatyka\\ 
11.4 Sztuczna inteligencja\\ 
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{I. Computing methodologies\\
  I.2. Artificial intelligence\\
  I.2.1. Applications and expert systems}

% S³owa kluczowe:
\keywords{sztuczna inteligencja, gry, Splits, alfabeta, monte carlo}

% Tu jest dobre miejsce na Twoje w³asne makra i~¶rodowiska:
\newtheorem{defi}{Definicja}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
  W pracy zaimplementowano oraz prztestowano metody sztucznej inteligencji w grach na przyk³adie gry planszowej Splits.
  W¶ród zbadanych metod znajduj± siê miêdzy innymi alfabeta, monte carlo i mcts wraz z ulepszeniami takimi jak
  tablica transpozycji. Ró¿nice w efektywno¶ci poszczególnych algorytmów zosta³y zbadane, a ich analiza mo¿e
  pomóc zdecydowaæ o charakterze gry Splits (strategiczny lub kombinacyjny).
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter*{Wprowadzenie}
\addcontentsline{toc}{chapter}{Wprowadzenie}

Za pomoc± gier mo¿na modelowaæ wiele zjawisk w dziedzinach ekonomii, matematyki i informatyki. Nie dziwi zatem dynamiczny
rozwój metod sztucznej inteligencji w grach. 

Istnieje wiele gier: zaczynaj±c od znanych i klasycznych jak go lub szachy, a koñcz±c na wspó³czesnych grach planszowych
wymy¶lanych dla celów rorywkowych. Wiele z tych ostatnich, aby zostaæ zauwa¿one na rynku, musz± wyró¿niaæ siê
niebanalnymi zasadami nieprzypominaj±cymi tych znanych z innych gier.

Jedn± z takich gier jest Splits. Bardzo du¿a ¶rednia ilo¶æ ruchów z pozycji a przy tym stosunkowo krótka rozgrywka
daj± szerokie pole dla badania efektywno¶ci algorytmów.

Praca sk³ada siê z czterech rozdzia³ów. W rozdziale 1 wprowadzono zasady gry Splits i pojêcia u¿ywane pó¼niej. Opis
u¿ytych technik sztucznej inteligencji zawarto w rozdziale 2. Rozdzia³ 3 przedstawia wyniki eksperymentów, w¶ród których
znalaz³y siê bezpo¶rednie rozgrywki miêdzy ró¿nymi algorytmami oraz testy usprawnieñ pokazuj±ce faktyczny zysk z danego
ulepszenia. W ostatnim rozdziale zawarto podsumowanie oraz przemy¶lenia na temat charakteru gry.

\chapter{Gra Splits}

``Splits'' to gra planszowa zaprojektowana przez w³oskiego projektanta gier Francesco Rotta, wydana w 2010 roku. 
Znana jest równie¿ pod tytu³ami ``Voll Shaft'' oraz ``Battle Sheep''.
Gra
szybko zdoby³a popularno¶æ dziêki ciekawym zasadom i ma³ej powtarzalno¶ci rozgrywki. W 2014 roku zdoby³a nawet rekomendacjê
jury ``Spiel des Jahres'' - uznanej niemieckiej nagrody dla najlepszych gier planszowych na niemieckojêzycznym
rynku.

\section{Zasady}

P³ytka w grze do pojedyczny element, z którego budowana jest plansza. Jest on podzielona na cztery sze¶ciok±ty foremne - tak zwane
heksy.

\begin{center}
\begin{tikzpicture}
  [scale=.1,auto=center, x=1mm, y=1mm]

  \draw [color=black] (0, 346) -- (100, 520) -- (300, 520) -- (400, 693) -- (600, 693) -- (700, 520);
  \draw [color=black] (0, 346) -- (100, 173) -- (300, 173) -- (400, 346) -- (300, 520);
  \draw [color=black] (300, 173) -- (400, 0) -- (600, 0) -- (700, 173) -- (600, 346) -- (400, 346);
  \draw [color=black] (600, 346) -- (700, 520) -- (900, 520) -- (1000, 346) -- (900, 173) -- (700, 173);
\end{tikzpicture}
\end{center}

¯eton to ma³y obiekt, których stos mo¿na umie¶ciæ na heksie. W grze jest 16 ¿etonów czarnych (gracza 0) oraz 16 ¿etonów bia³ych
(dla gracza 1).

Na pocz±tku gry umieszcza siê jedn± z p³ytek na ¶rodku sto³u. Nastêpnie gracze dok³adaj± na zmianê kolejne p³ytki buduj±c
w ten sposób planszê (zaczynaj±c od gracza 0). P³ytkê mo¿na umie¶ciæ na stole, je¿eli nie zachodzi na poprzednio
u³o¿one p³ytki oraz styka siê przynajmniej jedn± krawêdzi± heksa z heksem p³ytki ju¿ po³o¿onej na stole.

Gdy skoñcz± siê p³ytki, plansza jest zbudowana. Sk³ada siê z 32 heksów stanowi±cych spójny podzbiór zbioru heksów
pokrywaj±cych p³aszczyznê. Gracz 1 wybiera teraz heks, który znajduje siê przy zewnêtrznej krawêdzi planszy - to znaczy
taki, który przynajmniej jedn± krawêdzi± nie s±siaduje z innym heksem i ta pusta przestrzeñ nie jest ograniczona - nie mo¿e to
byæ ``dziura'' w planszy. Gracz 1 k³adzie na tym polu wszystkie swoje 16 ¿etonów. Gracz 0 postêpuje podobnie - nie mo¿e
ju¿ jednak wybraæ tego samego pola, co gracz 1.

W tym momencie zaczyna siê w³a¶ciwa rozgrywka. Zaczyna j± gracz 1, a potem ruchy wykonuje siê na zmianê, a¿ wykonanie ruchu
stanie siê niemo¿liwe. Gracz wykonuj±cy ruch wybiera dowolny stos ¿etonów na planszy i rozdziela go dowolnie na 2 nowe stosy.
Ka¿dy z nowych stosów musi byæ niepusty. Jeden ze stosów zostaje w miejscu, a drugi nale¿y przesun±æ tak daleko jak to mo¿liwe
w prostej linii wzd³u¿ linii heksów. Przesuniêcie musi byæ o co najmniej jedno pole. Podczas przesuwania stosu nale¿y go
zatrzymaæ, gdy tylko trafi siê na przeszkodê - inny stos lub krawêd¼ planszy. Nale¿y postawiæ wtedy stos tu¿ przed przeszkod±.

Gracz, który nie mo¿e ju¿ wykonaæ ruchu, przegrywa.

\section{Uwagi}

Zauwa¿my, ¿e podczas rozgrywki wykonujemy najpierw ustalon± liczbê ruchów - 9, aby zbudowaæ planszê i umie¶ciæ na niej
pocz±tkowe stosy. Rozwa¿my teraz nastêpuj±c± liczbê $x$ zale¿n± od sytuacji w grze: ilo¶æ wszystkich stosów. W ka¿dym
ruchu $x$ zwiêksza siê dok³adnie o 1. Zauwa¿my te¿, ¿e je¶li ilo¶æ stosów wynosi dok³adnie 32, to wszystkie one maj± wielko¶æ 1
i wszystkie pola na planszy s± zajête. Nie mo¿na wtedy zatem wykonaæ wiêcej ruchów. Zatem maksymalna ilo¶æ wszystkich ruchów
to $9+30 = 39$ ruchów. Oczywi¶cie spora czê¶æ rozgrywek bêdzie znacznie krótsza, poniewa¿ mo¿e siê zdarzyæ, ¿e jaki¶ stos
wiêkszy od 1 ¿etonu zostanie wcze¶niej zablokowany.

$39$ nie jest d³ug± rozgrywk± w porównaniu do klasycznych gier takich jak szachy (przeciêtnie 60 - 100 ruchów) czy go (ponad 200),
ale nadrabia to dosyæ du¿ym rozga³êzieniem drzewa gry. Szczególnie w trakcie budowania planszy jest ona bardzo du¿a - czasami
mo¿na wykonaæ nawet ponad 100 ró¿nych ruchów. Tak¿e w ostatniej fazie - podczas dzielenia stosów czynnik ten pozostaje wysoki
i wynosi 30 - 60 mo¿liwych ruchów w danym momencie.

Powoduje to, ¿e gra nie jest prosta i wymaga sprawdzenia wielu
ró¿nych mo¿liwo¶ci podczas obmy¶lania ruchu. Daje to szerokie pole do popisu dla wielu ró¿nych technik sztucznej inteligencji.

\chapter{Techniki sztucznej inteligencji}

W ogólno¶ci technik± sztucznej inteligencji nazywamy funkcjê stanu gry, której warto¶ci± jest ruch mo¿liwy do wykonania
w danym stanie. Aby przeprowadziæ rozgrywkê u¿ywaj±c sztucznej inteligencji, nale¿y w momencie zdecydowania siê na ruch
podawaæ warto¶æ tej funkcji, zazwyczaj obliczon± z pomoc± komputera.

\section{Minimax}

Gdyby¶my dysponowali moc± obliczeniow± i pamiêci± zdoln± w krótkim czasie obliczyæ pe³ne drzewo gry, wiadomo by³oby które
pozycje s± wygrywaj±ce, a które przegrywaj±ce i wystarczy³oby znajduj±c siê w sytuacji wygrywaj±cej wykonaæ ruch
do przegrywaj±cej. Niezale¿nie od strategii przeciwnika zagwarantuje nam to zwyciêstwo.

Niestety dysponujemy ograniczonymi ¶rodkami i nawet zbudowanie pe³nego drzewa do g³êboko¶ci 4 stanowi w Splits ju¿
dosyæ spory problem. To w³a¶nie stara siê zrobiæ algorytm Minimaks. Posiadaj±c jaki¶ sposób oceny sytuacji w grze, który
nazywaæ bêdziemy funkcj± oceniaj±c±, mo¿emy zbadaæ drzewo gry do pewnej ustalonej g³êboko¶ci i zdecydowaæ, który ruch
najbardziej siê nam op³aci, zak³adaj±c, ¿e przeciwnik bêdzie siê stara³ graæ tak, ¿eby wynik by³ jak najgorszy dla nas.

Sytuacje, czyli inaczej wêz³y w drzewie gry nazywamy typu max, je¿eli maksymalizujemy w nich warto¶ci funkcji oceniaj±cej
potomków (czyli s± to pozycje, w których ``my'' wykonujemy ruch), a te w których minimalizujemy, nazywamy typu min (rusza siê
przeciwnik).

Dla g³êboko¶ci 1 jest to trywialne. Wystarczy wybraæ ruch prowadz±cy do sytuacji o najlepszej warto¶ci funkcji oceniaj±cej (lub
najgorszej, je¶li rozwa¿amy ruch przeciwnika).
Dla g³êboko¶ci $n$, nale¿y wykonaæ minimaks g³êboko¶ci $n-1$ dla wszystkich sytuacji, do których prowadz± ruchy. Warto¶ci±
naszego wêz³a jest maksimum (minimum je¶li wêze³ jest typu min) warto¶ci wêz³ów potomnych.

\begin{algorithm}
\caption{Minimax}
\begin{algorithmic}[1]

  \Function{Minimax}{node}
  \If {node jest li¶ciem} \Return Ocena(node)
  \EndIf
  \If {node jest typu max} \Return max(Minimax(son) | son jest synem node)
  \Else {} \Return min(Minimax(son) | son jest synem node)
  \EndIf
  \EndFunction

\end{algorithmic}
\end{algorithm}

Dok³adny opis algorytmu minimax znajduje siê w pracy doktorskiej Aske Plaata \cite{ap96}.

\subsection{Funkcja oceniaj±ca}

Problem znalezienia dobrej funkcji oceniaj±cej jest bardzo trudny i zazwyczaj u¿ywa siê lu¼nego pomys³u heurystycznego
zale¿nego od danej gry.

Funkcja oceniaj±ca powinna byæ ³atwa do obliczenia, poniewa¿ jest podstawowym fragmentem algorytmu, który bêdzie
wielokrotnie powtarzany dla ró¿nych wêz³ów. Powinna te¿ faktycznie oddawaæ jakie¶ strategiczne przewagi danych sytuacji.
Oczywi¶cie sytuacja, w której gra zakoñczy³a siê naszym zwyciêstwem powinna zostaæ oceniona jak±¶ symboliczn± warto¶ci±
``nieskoñczono¶æ'', poniewa¿ na pewno jest co najmniej tak dobra jak ka¿da inna sytuacja. Analogicznie gra przegrana
powinna dostaæ ocenê ``minus nieskoñczono¶æ''.

Zauwa¿my, ¿e w grze teoretycznie mo¿emy rozstawiæ 16 stosów swojego koloru (ka¿dy wielko¶ci 1). Je¿eli który¶ z naszych stosów
zostanie zablokowany, nie mo¿emy u¿yæ ju¿ ¿etonów z niego. Wydaje siê, ¿e ma zatem przyjêcie nastêpuj±cej funkcji oceniaj±cej:
ilo¶æ w³asnych ¿etonów, którymi potencjalnie mo¿na siê ruszyæ minus analogiczna ilo¶æ ¿etonów przeciwnika. ¯etony, którymi
mo¿na siê ruszyæ to ¿etony z niezablokowanych stosów. Zauwa¿my, ¿e je¿eli warto¶æ tej funkcji bêdzie dodatnia i w pewnym momencie
gra siê zakoñczy, to wygramy.

\section{Alfabeta}

Algorytm minimax przegl±da wszystkie wêz³y w ustalonym poddrzewie, ale okazuje siê, ¿e nie jest to potrzebne w niektórych
sytuacjach, aby w dalszym ci±gu umieæ podaæ dok³adn± warto¶æ minimaxow± dla danej sytuacji. Spójrzmy na nastêpuj±c± sytuacjê,
gdzie wêze³ $a$ jest typu max, obliczyli¶my ju¿ warto¶ci wêz³ów ``b'' i ``d'', które wynosz± odpowiednio $2$ i $-1$.

\begin{center}
\begin{tikzpicture}
  [scale=.4,auto=left,every node/.style={circle,fill=blue!20}]
  \node (n1) at (5, 10) {a};
  \node (n2) at (2, 5) {b};
  \node (n3) at (8, 5) {c};
  \node (n4) at (6, 0) {d};
  \node (n5) at (10, 0) {e};

  \foreach \from/\to in {n1/n2, n1/n3, n3/n4, n3/n5}
    \draw (\from) -- (\to);
\end{tikzpicture}
\end{center}

Poniewa¿ wêze³ $c$ jest typu min, to jego warto¶æ wynosi co najwy¿ej $-1$. Jest zatem na pewno mniejsza ni¿ warto¶æ wêz³a
$b$, która wynosi $2$. Zatem warto¶æ wêz³a $a$ to $2$. Nie musimy wyliczaæ warto¶ci wêz³a $e$, aby to stwierdziæ.

Wprowadzenie oszczêdno¶ci tego typu do algorytmu minimax nazywa siê algorytmem Alfabeta. Wraz z ró¿nymi usprawnieniami
zosta³ dok³adnie opisany w \cite{ap96}.

\subsection{Tablica transpozycji}

Chocia¿ czêsto mówimy o drzewie gry, to tak naprawdê struktura sytuacji gry i ruchów prowadz±cych od jednych do drugich jest
DAGiem. Oznacza to, ¿e niektóre pary wêz³ów w drzewie odpowiadaj± tym samym sytuacjom. £atwo zauwa¿yæ, ¿e musz± siê wtedy on
znajdowaæ na tej samej g³êboko¶ci (w grze Splits), poniewa¿ na przyk³ad ilo¶æ stosów ¿etonów w grze odpowiada bijektywnie g³êboko¶ci
w drzewie. W takim razie warto¶æ minimaksowa obydwu wêz³ów musi byæ taka sama.

Naturalnym wydaje siê pomys³ wykorzystania tego faktu i unikniêcia powtórnego obliczania tej warto¶ci. Dobrym narzêdziem
w tym celu jest tablica transpozycji. Jest to tablica haszuj±ca, w której trzymamy warto¶ci minimaksowe sytuacji.
Pocz±tkowo trzymamy w niej jakie¶ umowne warto¶ci oznaczaj±ce niezainicjalizowany stan, a gdy uda nam siê obliczyæ warto¶æ
minimaks wêz³a, wpisujemy j± do tablicy. Zawsze gdy chcemy obliczyæ warto¶æ jakiego¶ wêz³a, sprawdzamy najpierw, czy nie znajduje
siê on ju¿ w tablicy.

%% TODO: cos o haszowaniu Zobrista?

\subsection{Iteracyjne pog³êbianie}

Zarówno przy minimaksie jak i przy alfabecie pojawia siê pojêcie drzewa przeszukiwania. Zazwyczaj jest ono zdefiniowane przez
g³êboko¶æ, na jak± zamierzamy przeprowadziæ przeszukiwanie. Pocz±tkowo ustalamy jak±¶ g³êboko¶æ, a nastêpnie zmniejszamy tê warto¶æ
w rekurencyjnym wywo³aniu. Li¶ciem drzewa przeszukiwañ jest wtedy wêze³, do którego weszli¶my z g³êboko¶ci± $0$ lub faktyczny
stan koñcowy gry.

Zauwa¿my, ¿e przeszukiwanie z g³êboko¶ci± zaledwie o jeden wiêksz± jest o ca³y rz±d wielko¶ci d³u¿sze, zatem je¿eli
dysponujemy ograniczonym czasem na ruch, mo¿emy zacz±æ od pewnej ustalonej niewielkiej g³êboko¶ci - na przyk³ad $1$, a nastêpnie
przeszukiwaæ na coraz wiêksze g³êboko¶ci, a¿ zabraknie nam czasu. Wynikiem iteracyjnego pog³êbiania jest wynik ostatniego
pe³nego przeszukania.

Ten algorytm jest szczególnie przydatny, je¿eli bardzo trudno jest okre¶liæ w³a¶ciw± g³êboko¶æ oraz gdy stopieñ
rozga³êzienia drzewa gry zmienia siê z czasem, tak jak jest w przypadku gry Splits, gdzie ilo¶æ mo¿liwych ruchów
bardzo szybko ro¶nie podczas budowania planszy, a potem spada w czasie w³a¶ciwej rozgrywki, ale wci±¿ pozostaje ma³o stabilny.

\begin{algorithm}
\caption{Iterative deepening}
\begin{algorithmic}[1]
  \Function{Iterative alphabeta} {node}
  \State $\textit{depth} \gets 1$
  \While {$\texttt{wci±¿ jest czas}$}
  \State $\textit{result} \gets \textit{Alphabeta}(node, depth)$
  \State $\textit{depth} \gets \textit{depth} + 1$
  \EndWhile
  \Return result
  \EndFunction
\end{algorithmic}
\end{algorithm}

\section{Monte Carlo}

Techniki Monte Carlo to w³a¶ciwie nie jeden algorytm, ale ca³a ich rodzina. Zastosowania metod Monte Carlo znajduj± siê nie tylko
w grach, ale równie¿ w statystyce czy rachunku ró¿niczkowym (zob. \cite{la87}). Najpro¶ciesz rzecz ujmuj±c, metoda ta polega
na wykonywaniu du¿ej liczby losowych symulacji i wyci±ganiu wniosków z wyników.

W przpadku gry symulacj± jest losowa rozgrywka, a wynikiem - numer gracza zwyciêskiego. Je¿eli z danej sytuacji
przprowadzimy du¿o losowych rozgrywek i wiêkszo¶æ z nich wygra³ gracz 0, to mo¿emy wnioskowaæ, ¿e jest to stosunkowo dobra sytuacja
dla tego gracza. Algorytm, który realizuje ten pomys³ zosta³ w projekcie nazwany po prostu ``monte carlo''.

Wiêcej o technikach Monte Carlo mo¿na znale¼æ w pracy \cite{mcts12}.

\begin{algorithm}
\caption{Monte Carlo}
\begin{algorithmic}[1]
  \Function{monteCarlo} {node}
  \While {$\texttt{wci±¿ jest czas}$}
  \State $\textit{son} \gets \textit{chooseSon}(node)$
  \State $\textit{simulate}(son)$
  \EndWhile
  \Return $\texttt{syn z najlepszymi wynikami}$
  \EndFunction
\end{algorithmic}
\end{algorithm}

W powy¿szym pseudokodzie funkcja $\textit{chooseSon}$ wybiera po prostu losowego syna, natomiast $\textit{simulate}$
przeprowadza ca³kowicie losow± rozgrywkê. Te funkcje mo¿na jednak zast±piæ nieco innymi, które prowadz± do ciekawych
odmian techniki Monte Carlo. Jedn± z nich jest wykorzystanie pojêcia granicy ufno¶ci.

\subsection{Monte Carlo z granic± ufno¶ci}

Zauwa¿my, ¿e przeprowadzaj±c algorytm Monte Carlo mo¿e siê zdarzyæ, ¿e jakie¶ dwa ruchy s± widocznie lepsze od trzeciego
ju¿ po niedu¿ej liczbie rozgrywek. Podstawowy algorytm wci±¿ jednak bêdzie wybiera³ wszystkie ruchy do symulacji
z tym samym prawdopodobieñstwem. Byæ mo¿e jednak lepiej by³oby zrezygnowaæ z czê¶ci rozgrywek przeznaczonych
na wyj±tkowo s³aby ruch, aby móc przeznaczyæ wiêcej w celu rozró¿nienia pomiêdzy dobrymi ruchami.

U¶ci¶leniem tego pomys³u jest pojêcie granicy ufno¶ci. Uzasadnienie wykorzystania w³a¶nie takich warto¶ci mo¿na
znale¼æ w \cite{mcts12}.

\begin{algorithm}
  \caption{Monte Carlo with confidency bound}
  \begin{algorithmic}
    \Function {ConfidencyBound} {node, son}
    \State $\textit{estimated} \gets \frac{\texttt{wygrane z son}}{\texttt{wszystkie rozgrywki son}}$
    \State $\textit{variance} \gets \sqrt{\frac{\log({\texttt{wszystkie rozgrywki node}})}{\texttt{wygrane z son}}}$
    \If {\texttt{node is of type max}} \Return $\textit{estimated} + \textit{variance}$
    \Else {} \Return $\textit{estimated} - \textit{variance}$
    \EndIf
    \EndFunction

    \Function {chooseSon} {node}
    {}\Return $\texttt{syn s stanu node optymalizuj±cy warto¶æ \textit{ConfidencyBound}(node, s)}$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\section{Monte Carlo Tree Search}

Algorytm przeszukiwania drzewa Monte Carlo to jeden z najmocniejszych znanych algorytmów sztucznej inteligencji w grach.
By³ on z sukcesem stosowany w grach takich jak go czy szachy. Stanowi on naturalne rozwiniêcie podstawowej techniki
Monte Carlo. Zauwa¿my, ¿e poprzednio decydowali¶my, który ruch wybraæ na podstawie wyników symulacji przeprowadzanych
z synów. Odpowiada to nieco sytuacji, w której przeprowadzamy minimaxa o g³êboko¶ci 1 z funkcj± oceniaj±c± na podstawie
losowych symulacji. Naturalnym pomys³em jest zwiêkszenie g³êboko¶ci i przeprowadzanie losowych rozgrywek dopiero
z li¶ci wybranego poddrzewa. Nie chcemy jednak traciæ zysków z wykorzystania granicy ufno¶ci, dlatego zamiast
zawsze dochodziæ do pe³nej g³êboko¶ci jak w minimaksie, bêdziemy powoli rozbudowywaæ drzewo tam, gdzie wydaje siê to
op³acalne. Pe³ny opis ró¿nych podej¶æ do przeszukiwania drzewa Monte Carlo mo¿na znale¼æ w \cite{mcts12}.

Poni¿ej zaprezentowano najbardziej klasyczne podej¶cie.

\begin{algorithm}
  \caption{Monte Carlo Tree Search}
  \begin{algorithmic}
    \Function {findBestMove} {node}
    \State $\texttt{utwórz korzeñ drzewa ze stanem \textit{node}}$
    \State $\texttt{rozwiñ drzewo w textit{node}}$
    \While {$\texttt{wci±¿ jest czas}$}
    \State $\textit{play}(node)$
    \EndWhile
    \Return $\texttt{syn s wêz³a \textit{node} optymalizuj±cy warto¶æ} \frac{\texttt{wygrane z s}}{\texttt{rozgrywki z s}}$
    \EndFunction


    \Function {play} {node}
    \If {$\texttt{\textit{node} jest li¶ciem}$}

    \If {$\texttt{przeprowadzono wystarczaj±co du¿o rozgrywek z \textit{node}}$}
    \State $\texttt{rozwiñ \textit{node}}$
    \State $\textit{result} \gets \textit{play}(\textit{chooseSon}(node))$
    \Else
    \State $\texttt{przeprowad¼ losow± rozgrywkê}$
    \Return $\texttt{1 dla wygranej, 0 dla przegranej}$
    \EndIf

    \Else
    \State $\textit{result} \gets \textit{play}(\textit{chooseSon}(node))$
    \EndIf

    \Return $\textit{result}$

    \EndFunction
  \end{algorithmic}
\end{algorithm}

W powy¿szym algorytmie stwierdzenie ``przeprowadzono wystarczaj±co du¿o rozgrywek'' mo¿na zrealizowaæ na ró¿ne sposoby.
Najprostszym jest ustalenie pewnej ustalonej liczby rozgrywek, po przekroczeniu której nale¿y rozwijaæ wêze³.

Zauwa¿my pewn± dodatkow± w³asno¶æ algorytmu. Statystyki liczby wygranych z poszczególnych wêz³ów s± tak samo dobre
teraz, jak i po faktycznym wykonaniu ruchów. Warto je zatem zachowaæ. Mo¿emy przechowaæ drzewo i gdy otrzymamy
informacjê, ¿e wykonano ruch, zamiast budowaæ drzewo od pocz±tku, mo¿emy po prostu przesun±æ wska¼nik korzenia
na odpowiedniego z synów.

\chapter{Wyniki ekperymentów}

W celu przeprowadzenia badañ zasady gry zosta³y zaimplementowane wraz z wariantami opisanych powy¿ej algorytmów.
Aby zbudowaæ aplikacjê nale¿y wej¶æ do katalogu splits, a nastêpnie wykonaæ:

\begin{algorithm}
  \begin{algorithmic}
    \State $\texttt{mkdir bin}$
    \State $\texttt{cd bin}$
    \State $\texttt{cmake ../src}$
    \State $\texttt{make}$
  \end{algorithmic}
\end{algorithm}

Nastêpnie mo¿na uruchamiaæ komendy opisane w poni¿szych sekcjach.

\section{Turniej}

%% Pierwszym testem algorytmu jest mecz z algorytmem wykonuj±cym zupe³nie losowe ruchy. Je¿eli nie napisano inaczej, przez
%% mecz bêdziemy rozumieæ grê z limitem czasu na ruch wielko¶ci 1 sekundy. Test
%% $\texttt{play\_match}$
%% uruchamia 5 meczy wybranych algorytmów. Na przyk³ad komenda:

%% \begin{algorithm}
%%   \begin{algorithmic}
%%     \State $\texttt{play\_match 0 1}$
%%   \end{algorithmic}
%% \end{algorithm}

%% uruchomi 5 meczów pomiêdzy algorytmem losowym, a minimax (algorytm losowy bêdzie zaczyna³). Numery poszczególnych algorytmów
%% to:

%% \begin{tabular}{|l|l|}
%% \hline
%% 0 & random \\
%% \hline
%% 1 & minimax \\
%% \hline
%% 2 & alphabeta \\
%% \hline
%% 3 & alphabeta with transposition table \\
%% \hline
%% 4 & monte carlo \\
%% \hline 
%% 5 & monte carlo with confidentiality bound \\
%% \hline
%% 6 & mcts \\
%% \hline
%% \end{tabular}

Najsensowniejszym sposobem przetestowania si³y algorytmu na tle innych jest rozegranie kilku partii z pozosta³ymi.
Program
\begin{algorithm}
  \begin{algorithmic}
    \State $\texttt{./tournament}$
  \end{algorithmic}
\end{algorithm}
³±czy ka¿dy program z ka¿dym innym na 2 sposoby - raz zaczyna jeden algorytm a raz drugi. W sumie ka¿da para ró¿nych
algorytmów rozgrywa 10 meczów. Przyjmuj±c poni¿sze numerowanie algorytmów:

\begin{tabular}{|l|l|}
\hline
0 & random \\
\hline
1 & minimax \\
\hline
2 & alphabeta \\
\hline
3 & alphabeta with transposition table \\
\hline
4 & monte carlo \\
\hline 
5 & monte carlo with confidentiality bound \\
\hline
6 & mcts \\
\hline
\end{tabular}

W tabeli przedstawiono wyniki przeprowadzenia turnieju. Liczba oznacza ilo¶æ gier wygranych przez gracza ``wierszowego'' na 5
meczów. Gracz ``wierszowy'' rozpoczyna³.

\begin{tabular}{|r|c|c|c|c|c|c|c|}
\hline
nr & 0 & 1 & 2 & 3 & 4 & 5 & 6 \\
\hline
0 & 2 & 1 & 1 & 1 & 0 & 0 & 0 \\
\hline
1 & 4 & 3 & 2 & 3 & 0 & 0 & 0 \\
\hline
2 & 5 & 2 & 2 & 1 & 0 & 0 & 0 \\
\hline
3 & 4 & 4 & 1 & 2 & 0 & 0 & 0 \\
\hline
4 & 5 & 5 & 5 & 5 & 3 & 2 & 0 \\
\hline
5 & 5 & 5 & 5 & 4 & 3 & 3 & 0 \\
\hline
6 & 5 & 5 & 5 & 5 & 3 & 3 & 2 \\
\hline
\end{tabular}

Wszystkie algorytmy poradzi³y sobie dosyæ dobrze z randomem. Jedynie minimaksowi i alfabetom zdarzy³o siê nie wygraæ do 0.
Prawdopodobnie wynika to z faktu, ¿e algorytmy te w fazie budowania planszy, gdy nie ma jeszcze ¿etonów, funkcja
oceniaj±ca zwraca zawsze 0, wiêc ruszaj± siê one losowo. Faktycznie zaczynaj± one wyliczaæ najlepszy ruch dopiero
po postawieniu ¿etonów, gdy mo¿e byæ za pó¼no. Istnieje zatem szansa, ¿e losowy algorytm je pokona.

Techniki monte carlo nie maj± tego problemu. S± ca³kowicie niezale¿ne od heurystyk i poradzi³y sobie znakomicie
zarówno z randomem jak i z technikami opartymi o funkcjê oceniaj±c±.

\section{Alfabeta}

Przyjrzymy siê teraz przyspieszeniu jakie daje mo¿liwo¶æ dokonywania odciêæ przez alfabetê oraz sprawdzania tablicy transpozycji.
Wszystkie algorytmy $\texttt{minimax}$, $\texttt{alphabeta}$ oraz $\texttt{alphabeta\_with\_transposition\_table}$ ustawione
na tê sam± g³êboko¶æ obliczaj± warto¶æ minimaksow± tego samego drzewa. Test $alphabeta\_speeds$ doprowadza grê do przeciêtnego
momentu w fazie przek³adania ¿etonów i uruchamia wszystkie 3 algorytmy na g³êboko¶ci 4. Czasy potrzebne na obliczenie
warto¶ci drzewa przedstawiono w tabeli.

\begin {tabular}{|c|c|}
\hline
Algorytm & Czas [ms] \\
\hline
minimax & 22291 \\
\hline
alfabeta & 21982 \\
\hline
alfabeta z tablic± transpozycji & 19454 \\
\hline
\end{tabular}

Widaæ, ¿e ka¿de ulepszenie spowodowa³o pewien wzrost prêdko¶ci, jednak prawdopodobnie wiêkse ró¿nice pojawi³yby siê dopiero
przy wiêkszych g³êboko¶ciach. W sytuacji, gdy mamy tylko 1 sekundê na ruch w meczu, prawdopodobnie wszystkie algorytmy
wykonywa³y przeszukanie na tê sam± wysoko¶æ, nie licz±c sytuacji, gdy rozga³êzienie drzewa maleje, jak na przyk³ad pod koniec
gry. Dlatego nie widaæ znacz±cej przewagi alfabety z tablic± transpozycji nad pozosta³ymi dwoma algorytmami w turnieju.


\chapter{Podsumowanie}


\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem[MCTS12]{mcts12} C. Brown, E. Powley, D. Whitehouse, S. Lucas, P. I. Cowling, P. Rohlsfhagen, S. Tavener, D. Perez,
  S. Samothrakis, S. Colton, \textit{A Survey of Monte Carlo Tree Search Methods},
  IEEE Transactions on Computational Intelligence and AI in Games, vol.4, no.1 (2012)

\bibitem[LA87]{la87} N. Metropolis, \textit{The Beginning of the Monte Carlo Method}, Los Alamos Science Special Issue (1987),
  125 - 130

\bibitem[AP96]{ap96} A. Plaat, \textit{Research, Re: search \& Re-search} (1996) 9 - 36

%% \bibitem[Bea65]{beaman} Juliusz Beaman, \textit{Morbidity of the Jollye
%%     function}, Mathematica Absurdica, 117 (1965) 338--9.

\end{thebibliography}

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
